{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting existing crawl.  Remove spider.sqlite to start a fresh crawl.\n",
      "['http://www.dr-chuck.com', 'https://elpais.com']\n",
      "How many pages:https://elpais.com/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'https://elpais.com/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cabbc33dad11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0msval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'How many pages:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mmany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmany\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'https://elpais.com/'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1.8841308641975305, 1.9517694458161867, 1, 'http://www.dr-chuck.com')\n",
      "(4, 2.2680197530864197, 2.2363811742112483, 2, 'http://www.dr-chuck.com/dr-chuck/resume/index.htm')\n",
      "(2, 0.9933530864197531, 1.00364265569273, 10, 'http://www.dr-chuck.com/dr-chuck/resume/bio.htm')\n",
      "(2, 0.8851185185185186, 0.889642971193416, 16, 'http://www.dr-chuck.com/dr-chuck/resume/speaking.htm')\n",
      "(2, 0.5434641975308643, 0.5502020384087793, 18, 'http://www.dr-chuck.com/dr-chuck/resume')\n",
      "(1, 1.0, 1.0, 3, 'http://www.dr-chuck.com/office')\n",
      "(1, 0.904846913580247, 0.8677360850480111, 4, 'http://www.dr-chuck.com/sakai-book')\n",
      "(1, 0.904846913580247, 0.8677360850480111, 5, 'http://www.dr-chuck.com/obi-sample')\n",
      "(1, 0.5434641975308643, 0.5502020384087793, 15, 'http://www.dr-chuck.com/dr-chuck/resume/leadership.htm')\n",
      "(1, 0.5434641975308643, 0.5502020384087793, 17, 'http://www.dr-chuck.com/dr-chuck/resume/pictures/index.htm')\n",
      "(1, 0.5292913580246915, 0.5324854677640606, 19, 'http://www.dr-chuck.com/dr-chuck/resume/pictures')\n",
      "11 rows.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "#sdumpy\n",
    "conn = sqlite3.connect('spider.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url \n",
    "     FROM Pages JOIN Links ON Pages.id = Links.to_id\n",
    "     WHERE html IS NOT NULL\n",
    "     GROUP BY id ORDER BY inbound DESC''')\n",
    "\n",
    "count = 0\n",
    "for row in cur :\n",
    "    if count < 50 : print(row)\n",
    "    count = count + 1\n",
    "print(count, 'rows.')\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many iterations:2\n",
      "1 0.05671484773662562\n",
      "2 0.03618162249657063\n",
      "[(1, 1.9517694458161867), (5, 0.8677360850480111), (4, 0.8677360850480111), (2, 2.2363811742112483), (10, 1.00364265569273)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "#spranky\n",
    "conn = sqlite3.connect('spider.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Find the ids that send out page rank - we only are interested\n",
    "# in pages in the SCC that have in and out links\n",
    "cur.execute('''SELECT DISTINCT from_id FROM Links''')\n",
    "from_ids = list()\n",
    "for row in cur: \n",
    "    from_ids.append(row[0])\n",
    "\n",
    "# Find the ids that receive page rank \n",
    "to_ids = list()\n",
    "links = list()\n",
    "cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')\n",
    "for row in cur:\n",
    "    from_id = row[0]\n",
    "    to_id = row[1]\n",
    "    if from_id == to_id : continue\n",
    "    if from_id not in from_ids : continue\n",
    "    if to_id not in from_ids : continue\n",
    "    links.append(row)\n",
    "    if to_id not in to_ids : to_ids.append(to_id)\n",
    "\n",
    "# Get latest page ranks for strongly connected component\n",
    "prev_ranks = dict()\n",
    "for node in from_ids:\n",
    "    cur.execute('''SELECT new_rank FROM Pages WHERE id = ?''', (node, ))\n",
    "    row = cur.fetchone()\n",
    "    prev_ranks[node] = row[0]\n",
    "\n",
    "sval = input('How many iterations:')\n",
    "many = 1\n",
    "if ( len(sval) > 0 ) : many = int(sval)\n",
    "\n",
    "# Sanity check\n",
    "if len(prev_ranks) < 1 : \n",
    "    print(\"Nothing to page rank.  Check data.\")\n",
    "    quit()\n",
    "\n",
    "# Lets do Page Rank in memory so it is really fast\n",
    "for i in range(many):\n",
    "    # print prev_ranks.items()[:5]\n",
    "    next_ranks = dict();\n",
    "    total = 0.0\n",
    "    for (node, old_rank) in list(prev_ranks.items()):\n",
    "        total = total + old_rank\n",
    "        next_ranks[node] = 0.0\n",
    "    # print total\n",
    "\n",
    "    # Find the number of outbound links and sent the page rank down each\n",
    "    for (node, old_rank) in list(prev_ranks.items()):\n",
    "        # print node, old_rank\n",
    "        give_ids = list()\n",
    "        for (from_id, to_id) in links:\n",
    "            if from_id != node : continue\n",
    "           #  print '   ',from_id,to_id\n",
    "\n",
    "            if to_id not in to_ids: continue\n",
    "            give_ids.append(to_id)\n",
    "        if ( len(give_ids) < 1 ) : continue\n",
    "        amount = old_rank / len(give_ids)\n",
    "        # print node, old_rank,amount, give_ids\n",
    "    \n",
    "        for id in give_ids:\n",
    "            next_ranks[id] = next_ranks[id] + amount\n",
    "    \n",
    "    newtot = 0\n",
    "    for (node, next_rank) in list(next_ranks.items()):\n",
    "        newtot = newtot + next_rank\n",
    "    evap = (total - newtot) / len(next_ranks)\n",
    "\n",
    "    # print newtot, evap\n",
    "    for node in next_ranks:\n",
    "        next_ranks[node] = next_ranks[node] + evap\n",
    "\n",
    "    newtot = 0\n",
    "    for (node, next_rank) in list(next_ranks.items()):\n",
    "        newtot = newtot + next_rank\n",
    "\n",
    "    # Compute the per-page average change from old rank to new rank\n",
    "    # As indication of convergence of the algorithm\n",
    "    totdiff = 0\n",
    "    for (node, old_rank) in list(prev_ranks.items()):\n",
    "        new_rank = next_ranks[node]\n",
    "        diff = abs(old_rank-new_rank)\n",
    "        totdiff = totdiff + diff\n",
    "\n",
    "    avediff = totdiff / len(prev_ranks)\n",
    "    print(i+1, avediff)\n",
    "\n",
    "    # rotate\n",
    "    prev_ranks = next_ranks\n",
    "\n",
    "# Put the final ranks back into the database\n",
    "print(list(next_ranks.items())[:5])\n",
    "cur.execute('''UPDATE Pages SET old_rank=new_rank''')\n",
    "for (id, new_rank) in list(next_ranks.items()) :\n",
    "    cur.execute('''UPDATE Pages SET new_rank=? WHERE id=?''', (new_rank, id))\n",
    "conn.commit()\n",
    "cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating JSON output on spider.js...\n",
      "How many nodes? 30\n",
      "Open force.html in a browser to view the visualization\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "#spjson\n",
    "conn = sqlite3.connect('spider.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"Creating JSON output on spider.js...\")\n",
    "howmany = int(input(\"How many nodes? \"))\n",
    "\n",
    "cur.execute('''SELECT COUNT(from_id) AS inbound, old_rank, new_rank, id, url \n",
    "    FROM Pages JOIN Links ON Pages.id = Links.to_id\n",
    "    WHERE html IS NOT NULL AND ERROR IS NULL\n",
    "    GROUP BY id ORDER BY id,inbound''')\n",
    "\n",
    "fhand = open('spider.js','w')\n",
    "nodes = list()\n",
    "maxrank = None\n",
    "minrank = None\n",
    "for row in cur :\n",
    "    nodes.append(row)\n",
    "    rank = row[2]\n",
    "    if maxrank is None or maxrank < rank: maxrank = rank\n",
    "    if minrank is None or minrank > rank : minrank = rank\n",
    "    if len(nodes) > howmany : break\n",
    "\n",
    "if maxrank == minrank or maxrank is None or minrank is None:\n",
    "    print(\"Error - please run sprank.py to compute page rank\")\n",
    "    quit()\n",
    "\n",
    "fhand.write('spiderJson = {\"nodes\":[\\n')\n",
    "count = 0\n",
    "map = dict()\n",
    "ranks = dict()\n",
    "for row in nodes :\n",
    "    if count > 0 : fhand.write(',\\n')\n",
    "    # print row\n",
    "    rank = row[2]\n",
    "    rank = 19 * ( (rank - minrank) / (maxrank - minrank) ) \n",
    "    fhand.write('{'+'\"weight\":'+str(row[0])+',\"rank\":'+str(rank)+',')\n",
    "    fhand.write(' \"id\":'+str(row[3])+', \"url\":\"'+row[4]+'\"}')\n",
    "    map[row[3]] = count\n",
    "    ranks[row[3]] = rank\n",
    "    count = count + 1\n",
    "fhand.write('],\\n')\n",
    "\n",
    "cur.execute('''SELECT DISTINCT from_id, to_id FROM Links''')\n",
    "fhand.write('\"links\":[\\n')\n",
    "\n",
    "count = 0\n",
    "for row in cur :\n",
    "    # print row\n",
    "    if row[0] not in map or row[1] not in map : continue\n",
    "    if count > 0 : fhand.write(',\\n')\n",
    "    rank = ranks[row[0]]\n",
    "    srank = 19 * ( (rank - minrank) / (maxrank - minrank) ) \n",
    "    fhand.write('{\"source\":'+str(map[row[0]])+',\"target\":'+str(map[row[1]])+',\"value\":3}')\n",
    "    count = count + 1\n",
    "fhand.write(']};')\n",
    "fhand.close()\n",
    "cur.close()\n",
    "\n",
    "print(\"Open force.html in a browser to view the visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pages set to a rank of 1.0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "#spresetpy\n",
    "conn = sqlite3.connect('spider.sqlite')\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''UPDATE Pages SET new_rank=1.0, old_rank=0.0''')\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "\n",
    "print(\"All pages set to a rank of 1.0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
